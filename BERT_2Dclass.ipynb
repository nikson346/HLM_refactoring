{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import EMdata\n",
    "import torch\n",
    "import itertools\n",
    "import random, math\n",
    "from collections import Counter\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU or CPU\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "device = torch.device(dev) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data path\n",
    "file_path='F:/script/class2vec/real_star_file/10340_case2_400_280.star'\n",
    "datatype=0 #0 is relion 3.1, 1 is relion 3, 2 is cryosparc\n",
    "block_size=64\n",
    "\n",
    "file_name=os.path.basename(file_path)\n",
    "output_path=os.path.dirname(file_path)+'/'+os.path.splitext(file_name)[0]\n",
    "if os.path.isdir(output_path) is False:\n",
    "    os.mkdir(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_rlnCoordinateX', '_rlnCoordinateY', '_rlnHelicalTubeID', '_rlnAngleTiltPrior', '_rlnAnglePsiPrior', '_rlnHelicalTrackLengthAngst', '_rlnAnglePsiFlipRatio', '_rlnImageName', '_rlnMicrographName', '_rlnOpticsGroup', '_rlnCtfMaxResolution', '_rlnCtfFigureOfMerit', '_rlnDefocusU', '_rlnDefocusV', '_rlnDefocusAngle', '_rlnCtfBfactor', '_rlnCtfScalefactor', '_rlnPhaseShift', '_rlnGroupNumber', '_rlnAngleRot', '_rlnAngleTilt', '_rlnAnglePsi', '_rlnOriginXAngst', '_rlnOriginYAngst', '_rlnClassNumber', '_rlnNormCorrection', '_rlnLogLikeliContribution', '_rlnMaxValueProbDistribution', '_rlnNrOfSignificantSamples']\n",
      "['3599.781488', '1124.560934', '1', '90.000000', '116.458355', '0.000000', '0.500000', '000001@Extract/job252/Case2/FoilHole_24943298_Data_24944182_24944183_20190125_1637-129188.mrcs', 'Case2/FoilHole_24943298_Data_24944182_24944183_20190125_1637-129188.mrc', '1', '4.172093', '0.180994', '16202.446289', '16096.935547', '54.328850', '0.000000', '1.000000', '0.000000', '1', '0.000000', '90.000000', '117.141810', '6.822705', '-3.33888', '41', '0.628615', '57319.949198', '0.038584', '36']\n",
      "finish reading\n",
      "finish converting\n",
      "[(41,  1,  0) (31,  2,  1) (41,  3,  2) (31,  4,  3) (39,  5,  4)\n",
      " (45,  6,  5) (31,  7,  6) (17,  8,  7) (39,  9,  8) (46, 10,  9)\n",
      " (49, 11, 10) (46, 12, 11) (49, 13, 12) (50, 14, 13) (41, 15, 14)\n",
      " (16, 16, 15) (16, 17, 16) (49, 18, 17) (49, 19, 18) (49, 20, 19)\n",
      " (49, 21, 20) (12, 22, 21)]\n",
      "[( 1, 1, 22) (10, 2, 23) (45, 3, 24) (45, 4, 25) ( 1, 5, 26) (14, 6, 27)]\n",
      "[(41,  1, 28) (39,  2, 29) ( 9,  3, 30) ( 6,  4, 31) (14,  5, 32)\n",
      " (14,  6, 33) (46,  7, 34) (44,  8, 35) (46,  9, 36) (44, 10, 37)\n",
      " (49, 11, 38) (49, 12, 39) (49, 13, 40)]\n",
      "[( 8, 1, 41) (41, 2, 42) (41, 3, 43) ( 6, 4, 44) (46, 5, 45) (46, 6, 46)\n",
      " (13, 7, 47) (13, 8, 48) (13, 9, 49)]\n",
      "[(16,  1, 50) (13,  2, 51) (12,  3, 52) (12,  4, 53) (41,  5, 54)\n",
      " (41,  6, 55) (41,  7, 56) (31,  8, 57) (31,  9, 58) (46, 10, 59)\n",
      " (19, 11, 60) (19, 12, 61)]\n"
     ]
    }
   ],
   "source": [
    "if datatype<2:\n",
    "    file_info=EMdata.read_relion(file_path)\n",
    "    if datatype==0:\n",
    "        #read data (relion3.1)\n",
    "        dataset=file_info.getRdata_31()\n",
    "        optics=file_info.extractoptic()\n",
    "    else:\n",
    "        #read relion 3.0\n",
    "        dataset=file_info.getRdata()\n",
    "    metadata=dataset[0]\n",
    "    print(metadata)\n",
    "    data=dataset[1]\n",
    "    print(data[0])\n",
    "    corpus_information=EMdata.process_helical(dataset).extarct_helical_select()\n",
    "else:\n",
    "    #read cryosparc\n",
    "    dataset=np.load(file_path)\n",
    "    corpus_information=EMdata.process_cryosparc_helical(dataset).extract_helical()\n",
    "corpus_dic,helix_name=corpus_information\n",
    "corpus=list(corpus_dic.values())\n",
    "corpus_backup=corpus[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3275.373196', '3255.318199', '1', '90.000000', '-40.45196', '0.000000', '0.500000', '000001@Extract/job252/Case2/FoilHole_24943300_Data_24944186_24944187_20190125_1834-129194.mrcs', 'Case2/FoilHole_24943300_Data_24944186_24944187_20190125_1834-129194.mrc', '1', '4.375610', '0.280399', '22421.539062', '22186.607422', '-58.36428', '0.000000', '1.000000', '0.000000', '4', '0.000000', '90.000000', '-40.35819', '-12.09953', '9.674396', '8', '0.630146', '57399.506287', '0.117411', '74']\n",
      "['3312.692842', '3287.138108', '1', '90.000000', '-40.45196', '56.399998', '0.500000', '000002@Extract/job252/Case2/FoilHole_24943300_Data_24944186_24944187_20190125_1834-129194.mrcs', 'Case2/FoilHole_24943300_Data_24944186_24944187_20190125_1834-129194.mrc', '1', '4.375610', '0.280399', '22421.539062', '22186.607422', '-58.36428', '0.000000', '1.000000', '0.000000', '4', '0.000000', '90.000000', '-40.35819', '-2.86189', '5.243915', '41', '0.632874', '57463.832057', '0.081440', '16']\n",
      "['3350.012488', '3318.958016', '1', '90.000000', '-40.45196', '112.799995', '0.500000', '000003@Extract/job252/Case2/FoilHole_24943300_Data_24944186_24944187_20190125_1834-129194.mrcs', 'Case2/FoilHole_24943300_Data_24944186_24944187_20190125_1834-129194.mrc', '1', '4.375610', '0.280399', '22421.539062', '22186.607422', '-58.36428', '0.000000', '1.000000', '0.000000', '4', '0.000000', '90.000000', '-45.98319', '-3.76052', '0.542680', '41', '0.631404', '57283.660790', '0.082230', '49']\n",
      "['3387.332134', '3350.777925', '1', '90.000000', '-40.45196', '169.199993', '0.500000', '000004@Extract/job252/Case2/FoilHole_24943300_Data_24944186_24944187_20190125_1834-129194.mrcs', 'Case2/FoilHole_24943300_Data_24944186_24944187_20190125_1834-129194.mrc', '1', '4.375610', '0.280399', '22421.539062', '22186.607422', '-58.36428', '0.000000', '1.000000', '0.000000', '4', '0.000000', '90.000000', '-45.98319', '-7.96853', '6.708046', '6', '0.633339', '57165.572889', '0.092771', '10']\n",
      "['3424.651780', '3382.597834', '1', '90.000000', '-40.45196', '225.599991', '0.500000', '000005@Extract/job252/Case2/FoilHole_24943300_Data_24944186_24944187_20190125_1834-129194.mrcs', 'Case2/FoilHole_24943300_Data_24944186_24944187_20190125_1834-129194.mrc', '1', '4.375610', '0.280399', '22421.539062', '22186.607422', '-58.36428', '0.000000', '1.000000', '0.000000', '4', '0.000000', '90.000000', '-45.98319', '-8.30903', '5.891221', '46', '0.632404', '57086.607538', '0.116363', '15']\n",
      "['3461.971426', '3414.417742', '1', '90.000000', '-40.45196', '281.999989', '0.500000', '000006@Extract/job252/Case2/FoilHole_24943300_Data_24944186_24944187_20190125_1834-129194.mrcs', 'Case2/FoilHole_24943300_Data_24944186_24944187_20190125_1834-129194.mrc', '1', '4.375610', '0.280399', '22421.539062', '22186.607422', '-58.36428', '0.000000', '1.000000', '0.000000', '4', '0.000000', '90.000000', '-45.98319', '-2.00264', '1.842622', '46', '0.636800', '56961.727479', '0.106539', '14']\n",
      "['3499.291072', '3446.237651', '1', '90.000000', '-40.45196', '338.399986', '0.500000', '000007@Extract/job252/Case2/FoilHole_24943300_Data_24944186_24944187_20190125_1834-129194.mrcs', 'Case2/FoilHole_24943300_Data_24944186_24944187_20190125_1834-129194.mrc', '1', '4.375610', '0.280399', '22421.539062', '22186.607422', '-58.36428', '0.000000', '1.000000', '0.000000', '4', '0.000000', '90.000000', '-45.98319', '-5.32804', '2.924871', '13', '0.635057', '56921.627727', '0.103276', '16']\n"
     ]
    }
   ],
   "source": [
    "look_data=dataset[1]\n",
    "variable=dataset[0]\n",
    "print(look_data[41])\n",
    "print(look_data[42])\n",
    "print(look_data[43])\n",
    "print(look_data[44])\n",
    "print(look_data[45])\n",
    "print(look_data[46])\n",
    "print(look_data[47])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cryosparc\n",
    "#corpus_ignore=corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_ignore=[]\n",
    "for i in range(len(corpus)):\n",
    "    corpus_row=[]\n",
    "    count=1\n",
    "    lst=corpus[i]\n",
    "    for j in range(len(lst)):\n",
    "        particle=lst[j]\n",
    "        if j==0:\n",
    "            count+=particle[1]-1\n",
    "        if count==int(particle[1]):\n",
    "            corpus_row.append(str(particle[0]))\n",
    "            count+=1\n",
    "        else:\n",
    "            while 1:\n",
    "                if count==int(lst[j][1]):\n",
    "                    corpus_row.append(str(particle[0]))\n",
    "                    count+=1\n",
    "                    break\n",
    "                corpus_row+=['0']\n",
    "                count+=1               \n",
    "    corpus_ignore.append(corpus_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3595\n"
     ]
    }
   ],
   "source": [
    "print(helix_name.index('Extract/job252/Case2/FoilHole_24950850_Data_24944178_24944179_20190127_0912-131918.mrcs-1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['37', '4', '23', '4', '4', '4', '38', '4', '4', '4', '33', '4', '4', '33', '4', '33', '4', '33', '33', '33', '33', '4']\n"
     ]
    }
   ],
   "source": [
    "print(corpus_ignore[3595])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus_length_histogram=[]\n",
    "for i in range(len(corpus_ignore)):\n",
    "    corpus_length_histogram.append(len(corpus_ignore[i]))\n",
    "bins=max(corpus_length_histogram)\n",
    "print(bins)\n",
    "plt.hist(corpus_length_histogram,list(range(0,max(corpus_length_histogram)+10,1)))\n",
    "#plt.ylim((0,1000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = set(itertools.chain.from_iterable(corpus_ignore))\n",
    "vocabulary_size = len(vocabulary)\n",
    "print(vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = {w: idx for (idx, w) in enumerate(vocabulary)}\n",
    "index_to_word = {idx: w for (idx, w) in enumerate(vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "if os.path.isdir(output_path+\"/corpus\") is False:\n",
    "    os.mkdir(output_path+\"/corpus\")\n",
    "paths = [str(x) for x in Path(output_path+\"/corpus/\").glob(\"**/*.txt\")]\n",
    "\n",
    "# Initialize a tokenizer\n",
    "tokenizer = ByteLevelBPETokenizer()\n",
    "\n",
    "# Customize training\n",
    "tokenizer.train(files=paths, vocab_size=vocabulary_size, min_frequency=2, special_tokens=[\n",
    "    \"<s>\",\n",
    "    \"<pad>\",\n",
    "    \"</s>\",\n",
    "    \"<unk>\",\n",
    "    \"<mask>\",\n",
    "])\n",
    "if os.path.isdir(output_path+\"/tokens\") is False:\n",
    "    os.mkdir(output_path+\"/tokens\")\n",
    "if os.path.isdir(\"./tokens\") is False:\n",
    "    os.mkdir(\"./tokens\")\n",
    "tokenizer.save_model(output_path+\"/tokens\")\n",
    "tokenizer.save_model(\"./tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(output_path+'/tokens/vocab.json') as f:\n",
    "    decode = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode={value:key for (key, value) in decode.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_code=[]\n",
    "for i in range(len(corpus_ignore)):\n",
    "    lst=corpus_ignore[i]\n",
    "    corpus_row=[]\n",
    "    for j in range(len(lst)):\n",
    "        corpus_row.append(encode[word_to_index[lst[j]]+5])\n",
    "    corpus_code.append(corpus_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_path+\"/corpus/helical.txt\",\"w\") as f:\n",
    "    for i in range(len(corpus_code)):\n",
    "        lst=corpus_code[i]\n",
    "        for j in range(len(lst)):\n",
    "            if j==len(lst)-1:\n",
    "                f.write(lst[j]+'\\n')\n",
    "            else:\n",
    "                f.write(lst[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(output_path+\"/tokens\", max_len=514)\n",
    "#tokenizer.encode(encode[word_to_index['0']+5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig\n",
    "\n",
    "config = RobertaConfig(\n",
    "    vocab_size=50_000,\n",
    "    max_position_embeddings=128,\n",
    "    num_attention_heads=12,\n",
    "    num_hidden_layers=6,\n",
    "    type_vocab_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForMaskedLM\n",
    "\n",
    "model = RobertaForMaskedLM(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from transformers import LineByLineTextDataset\n",
    "\n",
    "data_import = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=output_path+\"/corpus/helical.txt\",\n",
    "    block_size=block_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(data_import))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=data_import,\n",
    "    prediction_loss_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(output_path+\"/tokens/\")\n",
    "trainer.save_model(\"./tokens/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "feature_extraction = pipeline(\n",
    "    'feature-extraction',model=\"./tokens\",tokenizer=\"./tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.shape(feature_extraction(encode[word_to_index['50']+5])))\n",
    "#print(np.squeeze(feature_extraction('DGG'))[0]-np.squeeze(feature_extraction('JJ'))[0])\n",
    "print(''.join(corpus_code[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def select_random(corpus,number):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_corpus(corpus,cut_length):\n",
    "    new_corpus=[]\n",
    "    cut_length=cut_length\n",
    "    print(len(corpus))\n",
    "    for i in range(len(corpus)):\n",
    "        lst=corpus[i]\n",
    "        n=len(lst)\n",
    "        if n<=cut_length:\n",
    "            new_corpus.append(lst)\n",
    "            continue\n",
    "        if n%cut_length==0:\n",
    "            cut_amount=int(n/cut_length)\n",
    "        else:\n",
    "            cut_amount=int((n-n%cut_length)/cut_length)+1\n",
    "        for j in range(cut_amount-1):\n",
    "            new_corpus.append(lst[j*cut_length:(j+1)*cut_length])\n",
    "        new_corpus.append(lst[(cut_amount-1)*cut_length:])\n",
    "    print(len(new_corpus))\n",
    "    return new_corpus\n",
    "corpus_code_cut=cut_corpus(corpus_code,block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filament_embeddings=[]\n",
    "for i in range(len(corpus_code_cut)):\n",
    "    if i%200==0:\n",
    "        print(i)\n",
    "    lst=list(np.squeeze(feature_extraction(''.join(corpus_code_cut[i])))[0])\n",
    "    filament_embeddings.append(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(''.join(corpus_code_cut[3938][12:-5]))\n",
    "lst=list(np.squeeze(feature_extraction(''.join(corpus_code_cut[3938])[12:23])))\n",
    "print(len(corpus_code_cut[3938][11:-5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(''.join(corpus_code_cut[77]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans,SpectralClustering,MeanShift, estimate_bandwidth,DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import multivariate_normal \n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filament_embeddings=np.array(filament_embeddings)\n",
    "mask_1 = np.isfinite(filament_embeddings).all(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filament_embeddings[mask_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_sum = PCA(n_components=2).fit_transform(filament_embeddings)\n",
    "#cluster_pca = KMeans(n_clusters=3).fit_predict(pca_sum[0:len(corpus)])\n",
    "pca_sum_hD = PCA(n_components=30).fit_transform(filament_embeddings)\n",
    "\n",
    "plt.figure(figsize = (20, 20))\n",
    "plt.scatter(pca_sum[:,0], pca_sum[:,1],alpha=0.6,color='blue')\n",
    "plt.savefig(output_path+'/'+os.path.splitext(file_name)[0]+\"_bert_pca.png\",bbox_inches='tight', pad_inches=0.01)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_neighbors=15\n",
    "min_dist=0.1\n",
    "#umap_ND=umap.UMAP(n_neighbors=200,min_dist=0.4,n_components=100).fit_transform(filament_embeddings)\n",
    "reducer = umap.UMAP(n_neighbors=n_neighbors,min_dist=min_dist)\n",
    "umap_2D = reducer.fit_transform(filament_embeddings)\n",
    "umap_ND=umap.UMAP(n_neighbors=n_neighbors,min_dist=min_dist,n_components=100).fit_transform(filament_embeddings)\n",
    "print('finish umap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_path+'/'+'umap_3D_bert.npy', 'wb') as f:\n",
    "    np.save(f, umap_ND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filament_cluster_number=2\n",
    "umap_predict=SpectralClustering(n_clusters=filament_cluster_number).fit_predict(umap_ND)\n",
    "#umap_predict=DBSCAN(eps=0.41, min_samples=100).fit_predict(umap_2D)+1\n",
    "#filament_cluster_number=len(np.unique(umap_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 20))\n",
    "\n",
    "for i in range(filament_cluster_number):\n",
    "    locals()['labels'+str(i)]=mpatches.Patch(color=plt.cm.tab20((i)/filament_cluster_number), \n",
    "                                             label=str(i)+' : '+str(np.count_nonzero(umap_predict==i)))\n",
    "plt.legend(handles=[eval('labels'+str(i)) for i in range(filament_cluster_number)])\n",
    "plt.scatter(umap_2D[:,0], umap_2D[:,1],alpha=0.6,c=plt.cm.tab20((umap_predict)/filament_cluster_number))\n",
    "#plt.scatter(umap_2D[:,0], umap_2D[:,1],alpha=0.4,c='blue')\n",
    "#plt.xlim((-20,20))\n",
    "#plt.ylim((-10,20))\n",
    "plt.savefig(output_path+'/'+os.path.splitext(file_name)[0]+\"_bert_umap_blue.png\",bbox_inches='tight', pad_inches=0.01)\n",
    "#c=plt.cm.tab20((umap_predict+1)/filament_cluster_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(filament_cluster_number):\n",
    "    cluster_name='cluster'+str(i)\n",
    "    cluster_nameID='clusterID'+str(i)\n",
    "    locals()[cluster_name]=[]\n",
    "    locals()[cluster_nameID]=[]\n",
    "data_line=0\n",
    "cluster_choice=umap_predict\n",
    "positive_label=[]\n",
    "for i in range(len(corpus_code_cut)):\n",
    "    lst=corpus_code_cut[i]\n",
    "    cluster_number=cluster_choice[i]\n",
    "    cluster_name='cluster'+str(cluster_number)\n",
    "    cluster_nameID='clusterID'+str(cluster_number)\n",
    "    for j in range(len(lst)):\n",
    "        locals()[cluster_name].append(data[data_line])\n",
    "        locals()[cluster_nameID].append(data[data_line][7][18:21])\n",
    "        data_line+=1\n",
    "    positive_label.append(locals()[cluster_nameID][-1])\n",
    "positive_label=np.array(positive_label)\n",
    "labels=list(np.unique(positive_label))\n",
    "positive_label_new=np.array([float(labels.index(x)) for x in positive_label])\n",
    "labels_name=['singlet','doublet'] # define the type of filaments \n",
    "clustersize=[]\n",
    "for i in range(filament_cluster_number):\n",
    "    clustersize.append(len(locals()['cluster'+str(i)]))\n",
    "print(clustersize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0][7][18:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 20))\n",
    "for i in range(len(labels_name)):\n",
    "    locals()['true_label'+str(i)]=mpatches.Patch(color=plt.cm.tab20(i/3), label=labels_name[i])\n",
    "plt.legend(handles=[eval('true_label'+str(i)) for i in range(len(labels))])\n",
    "print(len(positive_label))\n",
    "plt.scatter(umap_2D[:,0], umap_2D[:,1],color=plt.cm.tab20(positive_label_new/3),alpha=0.4)\n",
    "plt.savefig(output_path+'/'+os.path.splitext(file_name)[0]+\"_bert_umap_label.png\",bbox_inches='tight', pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_hist_all=[]\n",
    "for i in range(filament_cluster_number):\n",
    "    distribution_hist=[]\n",
    "    lst=locals()['clusterID'+str(i)]\n",
    "    for j in range(len(labels)):\n",
    "        group_percentage=lst.count(labels[j])/len(lst)\n",
    "        distribution_hist.append(group_percentage)\n",
    "    distribution_hist_all.append(distribution_hist)\n",
    "print(distribution_hist_all)\n",
    "print(len(data),len(cluster0),len(cluster1))\n",
    "\n",
    "fig, ax = plt.subplots(1,filament_cluster_number,figsize = (5*filament_cluster_number,7))\n",
    "\n",
    "for i in range(filament_cluster_number):\n",
    "    ax[i].bar(range(len(labels)),distribution_hist_all[i],tick_label =labels_name)\n",
    "    particle_number=len(locals()['cluster'+str(i)])\n",
    "    ax[i].set_title('cluster{} amount: {}'.format(i,particle_number))\n",
    "plt.savefig(output_path+'/'+os.path.splitext(file_name)[0]+'distr_new_bert.png')\n",
    "print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(filament_cluster_number):\n",
    "    cluster_name='cluster'+str(i)\n",
    "    data_cluster=locals()[cluster_name]\n",
    "    if datatype==0:\n",
    "        output=EMdata.output_star(output_path+'/bert_'+file_name,i,data_cluster,metadata)\n",
    "        output.opticgroup(optics)\n",
    "        output.writecluster()\n",
    "    elif datatype==1:\n",
    "        output=EMdata.output_star(output_path+'/'+file_name,i,data_cluster,metadata)\n",
    "        output.writemetadata()\n",
    "        output.writecluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
